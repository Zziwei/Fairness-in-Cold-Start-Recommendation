{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import copy\n",
    "import operator\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import coo_matrix\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhuziwei/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid   iid\n",
       "0    1  1193\n",
       "1    1   661"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./ratings.dat', header=None, sep='::')\n",
    "df.drop(columns=[2, 3], inplace=True)\n",
    "df.rename(columns={0: 'uid', 1: 'iid'}, inplace=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iid             title                                       genres\n",
       "0    1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy\n",
       "1    2    Jumanji (1995)                   Adventure|Children|Fantasy"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_df = pd.read_csv('../ml20m/movies.csv')\n",
    "item_df.rename(columns={'movieId': 'iid'}, inplace=True)\n",
    "item_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>tagId</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iid  tagId  relevance\n",
       "0    1      1      0.025\n",
       "1    1      2      0.025"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df = pd.read_csv('../ml20m/genome-scores.csv')\n",
    "feature_df.rename(columns={'movieId': 'iid'}, inplace=True)\n",
    "feature_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete items from feature_df that have all zero features\n",
    "f_item_list = feature_df['iid'].unique()\n",
    "f_score_list = feature_df['relevance'].values\n",
    "f_score_mat = f_score_list.reshape((-1, np.max(feature_df['tagId'])))\n",
    "keep_idx = np.where(np.sum(f_score_mat, axis=1) != 0)[0]\n",
    "keep_item_f = f_item_list[keep_idx]\n",
    "feature_df = feature_df[feature_df['iid'].isin(keep_item_f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove record for items which do not have features from df\n",
    "df = df[df['iid'].isin(keep_item_f)]\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove items which do not have features from item_df\n",
    "item_df = item_df[item_df['iid'].isin(keep_item_f)]\n",
    "item_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Drama', 5037),\n",
       " ('Comedy', 3742),\n",
       " ('Thriller', 2010),\n",
       " ('Romance', 1754),\n",
       " ('Action', 1720),\n",
       " ('Crime', 1250),\n",
       " ('Adventure', 1176),\n",
       " ('Horror', 1025),\n",
       " ('Sci-Fi', 909),\n",
       " ('Fantasy', 695),\n",
       " ('Children', 620),\n",
       " ('Mystery', 615),\n",
       " ('Documentary', 468),\n",
       " ('Animation', 459),\n",
       " ('War', 440),\n",
       " ('Musical', 401),\n",
       " ('Western', 219),\n",
       " ('IMAX', 164),\n",
       " ('Film-Noir', 112),\n",
       " ('(no genres listed)', 1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number for each genre and sort\n",
    "item_genre_dict = dict()\n",
    "for i in range(len(item_df)):\n",
    "    genre_str = item_df.at[i, 'genres']\n",
    "    genre_list = genre_str.split('|')\n",
    "    item_genre_dict[item_df.at[i, 'iid']] = genre_list\n",
    "\n",
    "genre_item_count = dict()\n",
    "for l in item_genre_dict:\n",
    "    for g in item_genre_dict[l]:\n",
    "        if not g in genre_item_count:\n",
    "            genre_item_count[g] = 1\n",
    "        else:\n",
    "            genre_item_count[g] += 1\n",
    "\n",
    "genre_count_sorted = sorted(genre_item_count.items(), key=operator.itemgetter(1), reverse=True)\n",
    "genre_count_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sci-Fi', 176.25302530253026),\n",
       " ('Adventure', 168.77636054421768),\n",
       " ('Action', 147.5732558139535),\n",
       " ('Film-Noir', 132.90178571428572),\n",
       " ('Fantasy', 130.9453237410072),\n",
       " ('Children', 128.81612903225806),\n",
       " ('War', 122.25454545454545),\n",
       " ('Thriller', 119.21094527363184),\n",
       " ('Musical', 118.9077306733167),\n",
       " ('Mystery', 118.81138211382114),\n",
       " ('Western', 113.77168949771689),\n",
       " ('Crime', 112.1328),\n",
       " ('Romance', 107.38768529076397),\n",
       " ('Comedy', 103.60208444681989),\n",
       " ('Animation', 96.04575163398692),\n",
       " ('Drama', 87.14592019058964),\n",
       " ('Horror', 84.64487804878048),\n",
       " ('IMAX', 24.78048780487805),\n",
       " ('Documentary', 16.337606837606838)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate feedback/item_count for each genre\n",
    "genre_rating_count = dict()\n",
    "itemIds = df['iid'].values\n",
    "for i in range(len(itemIds)):\n",
    "    itemId = itemIds[i]\n",
    "    genres = item_genre_dict[itemId]\n",
    "    for g in genres:\n",
    "        if not g in genre_rating_count:\n",
    "            genre_rating_count[g] = 1.\n",
    "        else:\n",
    "            genre_rating_count[g] += 1.\n",
    "for g in genre_rating_count:\n",
    "    genre_rating_count[g] /= genre_item_count[g] * 1.\n",
    "genre_count_sorted = sorted(genre_rating_count.items(), key=operator.itemgetter(1), reverse=True)\n",
    "genre_count_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Action',\n",
       " 'Adventure',\n",
       " 'Animation',\n",
       " 'Children',\n",
       " 'Comedy',\n",
       " 'Crime',\n",
       " 'Documentary',\n",
       " 'Drama',\n",
       " 'Fantasy',\n",
       " 'Film-Noir',\n",
       " 'Horror',\n",
       " 'IMAX',\n",
       " 'Musical',\n",
       " 'Mystery',\n",
       " 'Romance',\n",
       " 'Sci-Fi',\n",
       " 'Thriller',\n",
       " 'War',\n",
       " 'Western'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_used = set(list(genre_rating_count.keys()))\n",
    "genres_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter items by genres\n",
    "delete_list = []\n",
    "for i in range(len(item_df)):\n",
    "    genre_str = item_df.at[i, 'genres']\n",
    "    genre_list = genre_str.split('|')\n",
    "    genre_overlap = genre_list\n",
    "    if genre_str == '(no genres listed)':\n",
    "        delete_list.append(i)\n",
    "item_df.drop(delete_list, inplace=True)\n",
    "keep_item_g = item_df['iid'].unique()\n",
    "item_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove record for movies which do not have genres\n",
    "df = df[df['iid'].isin(keep_item_g)]\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove items from feature_df which do not have genres\n",
    "feature_df = feature_df[feature_df['iid'].isin(keep_item_g)]\n",
    "feature_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item num = 3470\n",
      "user num = 6040\n"
     ]
    }
   ],
   "source": [
    "item_set = set(df['iid'].unique())\n",
    "user_set = set(df['uid'].unique())\n",
    "print('item num = ' + str(len(item_set)))\n",
    "print('user num = ' + str(len(user_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = copy.copy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteratively remove items and users with less than 20 reviews\n",
    "rdf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "while np.min(rdf['uid'].value_counts().values) <= 19:\n",
    "    rdf['user_freq'] = rdf.groupby('uid')['uid'].transform('count')\n",
    "    rdf.drop(rdf.index[rdf['user_freq'] <= 19], inplace=True)\n",
    "    rdf.reset_index(drop=True, inplace=True)\n",
    "    rdf['item_freq'] = rdf.groupby('iid')['iid'].transform('count')\n",
    "    rdf.drop(rdf.index[rdf['item_freq'] <= 19], inplace=True)\n",
    "    rdf.reset_index(drop=True, inplace=True)\n",
    "    rdf['user_freq'] = rdf.groupby('uid')['uid'].transform('count')\n",
    "    rdf.reset_index(drop=True, inplace=True)\n",
    "# rdf['uid'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf.drop(columns=['user_freq', 'item_freq'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie num = 3018\n",
      "user num = 6018\n",
      "sparsity: 0.05464058454193417\n"
     ]
    }
   ],
   "source": [
    "item_list = rdf['iid'].unique()\n",
    "user_list = rdf['uid'].unique()\n",
    "print('movie num = ' + str(len(item_list)))\n",
    "print('user num = ' + str(len(user_list)))\n",
    "print('sparsity: ' + str(len(rdf) * 1.0 / (len(user_list) * len(item_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove movies from item_df\n",
    "item_df = item_df[item_df['iid'].isin(item_list)]\n",
    "item_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove movies from feature_df\n",
    "feature_df = feature_df[feature_df['iid'].isin(item_list)]\n",
    "feature_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the user and item str id->int id dict\n",
    "i = 0\n",
    "user_old2new_id_dict = dict()\n",
    "for u in user_list:\n",
    "    if not u in user_old2new_id_dict:\n",
    "        user_old2new_id_dict[u] = i\n",
    "        i += 1\n",
    "j = 0\n",
    "item_old2new_id_dict = dict()\n",
    "for i in item_list:\n",
    "    if not i in item_old2new_id_dict:\n",
    "        item_old2new_id_dict[i] = j\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the str id of items in item_df to int id\n",
    "for i in range(len(item_df)):\n",
    "    item_df.at[i, 'iid'] = item_old2new_id_dict[item_df.at[i, 'iid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the str id of items in feature_df to int id\n",
    "iid_array = feature_df['iid'].values\n",
    "for i in range(len(iid_array)):\n",
    "    iid_array[i] = item_old2new_id_dict[iid_array[i]]\n",
    "feature_df['iid'] = iid_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rdf with int id for user and item\n",
    "userIds = rdf['uid'].values\n",
    "itemIds = rdf['iid'].values\n",
    "userIdsNew = copy.copy(userIds)\n",
    "itemIdsNew = copy.copy(itemIds)\n",
    "for i in range(len(userIds)):\n",
    "    userIdsNew[i] = user_old2new_id_dict[userIds[i]]\n",
    "    itemIdsNew[i] = item_old2new_id_dict[itemIds[i]]\n",
    "rdf['uid'] = userIdsNew\n",
    "rdf['iid'] = itemIdsNew\n",
    "item_list = rdf['iid'].unique()\n",
    "user_list = rdf['uid'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train, vali and test sets for cold start recommendation\n",
    "# cold test 20%\n",
    "# cold vali 5%\n",
    "cold_item_idx = np.random.choice(np.arange(len(item_list)), int(len(item_list) * 0.40), replace=False).tolist()\n",
    "cold_itemIds = item_list[cold_item_idx]\n",
    "test_idx = np.random.choice(np.arange(len(cold_itemIds)), int(len(cold_itemIds) * 3. / 4.), replace=False).tolist()\n",
    "vali_idx = list(set(range(len(cold_itemIds))) - set(test_idx))\n",
    "cold_test_itemIds = cold_itemIds[test_idx]\n",
    "cold_vali_itemIds = cold_itemIds[vali_idx]\n",
    "\n",
    "cold_test_df = rdf[rdf['iid'].isin(cold_test_itemIds)]\n",
    "cold_test_df.reset_index(drop=True, inplace=True)\n",
    "cold_vali_df = rdf[rdf['iid'].isin(cold_vali_itemIds)]\n",
    "cold_vali_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# train_df = rdf.drop(rdf[rdf['iid'].isin(cold_itemIds)].index, axis=0)\n",
    "# train_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train, vali, and test sets for warm start recommendation\n",
    "# warm test 20%\n",
    "# warm vali 5%\n",
    "warm_df = rdf.drop(rdf[rdf['iid'].isin(cold_itemIds)].index, axis=0)\n",
    "warm_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "train_df = warm_df.copy()\n",
    "\n",
    "train_ratio = 0.9\n",
    "vali_ratio = 0.1\n",
    "\n",
    "vali_size = int(vali_ratio * len(warm_df))\n",
    "\n",
    "vali_idx = np.random.choice(np.arange(len(train_df)), vali_size, replace=False).tolist()\n",
    "warm_vali_df = train_df.copy()\n",
    "warm_vali_df = warm_vali_df.loc[vali_idx]\n",
    "train_df.drop(vali_idx, axis=0, inplace=True)\n",
    "\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "warm_vali_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove users from warm and cold test and vali sets who are not in training set\n",
    "\n",
    "train_user_list = train_df['uid'].unique()\n",
    "warm_vali_df = warm_vali_df[warm_vali_df['uid'].isin(train_user_list)]\n",
    "# warm_test_df = warm_test_df[warm_test_df['uid'].isin(train_user_list)]\n",
    "cold_vali_df = cold_vali_df[cold_vali_df['uid'].isin(train_user_list)]\n",
    "cold_test_df = cold_test_df[cold_test_df['uid'].isin(train_user_list)]\n",
    "# warm_test_df.reset_index(drop=True, inplace=True)\n",
    "warm_vali_df.reset_index(drop=True, inplace=True)\n",
    "cold_vali_df.reset_index(drop=True, inplace=True)\n",
    "cold_test_df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove items from warm test and vali sets who are not in training set\n",
    "\n",
    "train_item_list = train_df['iid'].unique()\n",
    "warm_vali_df = warm_vali_df[warm_vali_df['iid'].isin(train_item_list)]\n",
    "warm_vali_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# warm_test_df = warm_test_df[warm_test_df['iid'].isin(train_item_list)]\n",
    "# warm_test_df.reset_index(drop=True, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf.to_csv('./rdf.csv', index=False)\n",
    "train_df.to_csv('./train_df.csv', index=False)\n",
    "warm_vali_df.to_csv('./warm_vali_df.csv', index=False)\n",
    "# warm_test_df.to_csv('./warm_test_df.csv', index=False)\n",
    "cold_vali_df.to_csv('./cold_vali_df.csv', index=False)\n",
    "cold_test_df.to_csv('./cold_test_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Drama', 1417),\n",
       " ('Comedy', 1096),\n",
       " ('Thriller', 569),\n",
       " ('Romance', 542),\n",
       " ('Action', 473),\n",
       " ('Adventure', 374),\n",
       " ('Crime', 326),\n",
       " ('Horror', 314),\n",
       " ('Sci-Fi', 273),\n",
       " ('Children', 256),\n",
       " ('Fantasy', 189),\n",
       " ('Mystery', 168),\n",
       " ('Musical', 131),\n",
       " ('War', 121),\n",
       " ('Animation', 103),\n",
       " ('Western', 69),\n",
       " ('Documentary', 57),\n",
       " ('Film-Noir', 40),\n",
       " ('IMAX', 5)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number for each genre and sort\n",
    "item_genre_dict = dict()\n",
    "for i in range(len(item_df)):\n",
    "    genre_str = item_df.at[i, 'genres']\n",
    "    genre_list = genre_str.split('|')\n",
    "    genre_overlap = set(genre_list).intersection(genres_used)\n",
    "    item_genre_dict[item_df.at[i, 'iid']] = list(genre_overlap)\n",
    "\n",
    "genre_item_count = dict()\n",
    "for l in item_genre_dict:\n",
    "    for g in item_genre_dict[l]:\n",
    "        if not g in genre_item_count:\n",
    "            genre_item_count[g] = 1\n",
    "        else:\n",
    "            genre_item_count[g] += 1\n",
    "\n",
    "genre_count_sorted = sorted(genre_item_count.items(), key=operator.itemgetter(1), reverse=True)\n",
    "genre_count_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('IMAX', 531.4),\n",
       " ('Sci-Fi', 337.5274725274725),\n",
       " ('Action', 319.737843551797),\n",
       " ('Adventure', 316.24598930481284),\n",
       " ('War', 291.25619834710744),\n",
       " ('Crime', 251.76687116564418),\n",
       " ('Fantasy', 245.1216931216931),\n",
       " ('Thriller', 245.06854130052724),\n",
       " ('Mystery', 238.80357142857142),\n",
       " ('Animation', 223.2621359223301),\n",
       " ('Western', 208.30434782608697),\n",
       " ('Comedy', 203.46989051094891),\n",
       " ('Romance', 201.19741697416976),\n",
       " ('Film-Noir', 192.075),\n",
       " ('Musical', 186.3969465648855),\n",
       " ('Drama', 175.23570924488357),\n",
       " ('Children', 170.5859375),\n",
       " ('Horror', 126.45222929936305),\n",
       " ('Documentary', 79.29824561403508)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate feedback/item_count for each genre\n",
    "genre_rating_count = dict()\n",
    "itemIds = train_df['iid'].values\n",
    "for i in range(len(itemIds)):\n",
    "    itemId = itemIds[i]\n",
    "    genres = item_genre_dict[itemId]\n",
    "    for g in genres:\n",
    "        if not g in genre_rating_count:\n",
    "            genre_rating_count[g] = 1\n",
    "        else:\n",
    "            genre_rating_count[g] += 1\n",
    "for g in genre_item_count:\n",
    "    genre_rating_count[g] /= genre_item_count[g] * 1.\n",
    "genre_count_sorted = sorted(genre_rating_count.items(), key=operator.itemgetter(1), reverse=True)\n",
    "genre_count_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df.reset_index(drop=True, inplace=True)\n",
    "item_df.to_csv('./item_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./item_genre_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(item_genre_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./info.pkl', 'wb') as f:\n",
    "    pickle.dump({'num_user': len(user_list), 'num_item': len(item_list)}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6018/6018 [00:04<00:00, 1318.94it/s]\n",
      "/home/zhuziwei/.local/lib/python3.6/site-packages/ipykernel_launcher.py:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/home/zhuziwei/.local/lib/python3.6/site-packages/ipykernel_launcher.py:41: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/home/zhuziwei/.local/lib/python3.6/site-packages/ipykernel_launcher.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/home/zhuziwei/.local/lib/python3.6/site-packages/ipykernel_launcher.py:44: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "# generate list of items users like in train, warm_vali, warm_test sets for each user\n",
    "\n",
    "num_item = len(item_list)\n",
    "num_user = len(user_list)\n",
    "\n",
    "user_train_like = [[] for _ in range(num_user)]\n",
    "# user_warm_test_like = [[] for _ in range(num_user)]\n",
    "user_warm_vali_like = [[] for _ in range(num_user)]\n",
    "user_cold_test_like = [[] for _ in range(num_user)]\n",
    "user_cold_vali_like = [[] for _ in range(num_user)]\n",
    "\n",
    "train_array = train_df[['uid', 'iid']].values\n",
    "warm_vali_array = warm_vali_df[['uid', 'iid']].values\n",
    "# warm_test_array = warm_test_df[['uid', 'iid']].values\n",
    "cold_vali_array = cold_vali_df[['uid', 'iid']].values\n",
    "cold_test_array = cold_test_df[['uid', 'iid']].values\n",
    "\n",
    "for u in tqdm(user_list):\n",
    "    idx = list(np.where(train_array[:, 0] == u)[0])\n",
    "    train_like = (train_array[idx, 1]).astype(int)\n",
    "    \n",
    "    idx = list(np.where(warm_vali_array[:, 0] == u)[0])\n",
    "    warm_vali_like = (warm_vali_array[idx, 1]).astype(int)\n",
    "    \n",
    "#     idx = list(np.where(warm_test_array[:, 0] == u)[0])\n",
    "#     warm_test_like = (warm_test_array[idx, 1]).astype(int)\n",
    "    \n",
    "    idx = list(np.where(cold_vali_array[:, 0] == u)[0])\n",
    "    cold_vali_like = (cold_vali_array[idx, 1]).astype(int)\n",
    "    \n",
    "    idx = list(np.where(cold_test_array[:, 0] == u)[0])\n",
    "    cold_test_like = (cold_test_array[idx, 1]).astype(int)\n",
    "    \n",
    "    user_train_like[u] = train_like\n",
    "    user_warm_vali_like[u] = warm_vali_like\n",
    "#     user_warm_test_like[u] = warm_test_like\n",
    "    user_cold_vali_like[u] = cold_vali_like\n",
    "    user_cold_test_like[u] = cold_test_like\n",
    "    \n",
    "np.save('./user_train_like.npy', np.array(user_train_like))\n",
    "np.save('./user_warm_vali_like.npy', np.array(user_warm_vali_like))\n",
    "# np.save('./user_warm_test_like.npy', np.array(user_warm_test_like))\n",
    "np.save('./user_cold_vali_like.npy', np.array(user_cold_vali_like))\n",
    "np.save('./user_cold_test_like.npy', np.array(user_cold_test_like))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "iid_list = feature_df['iid'].values.astype(int)\n",
    "tag_list = feature_df['tagId'].values.astype(int) - 1\n",
    "score_list = feature_df['relevance'].values\n",
    "\n",
    "feature_mat = coo_matrix((score_list, (iid_list, tag_list)), shape=(len(item_list), np.max(tag_list) + 1)).toarray()\n",
    "np.save('./item_content.npy', feature_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute audience size for all items in rdf, and convert the old item id to new id\n",
    "item_pop = np.array(rdf['iid'].value_counts())\n",
    "item_pop_id = np.array(rdf['iid'].value_counts().index)\n",
    "item_AS_list = np.zeros(len(rdf['iid'].unique()))\n",
    "for i in range(len(item_pop_id)):\n",
    "    item_AS_list[item_pop_id[i]] = item_pop[i]\n",
    "\n",
    "np.save('./item_audience_size_list.npy', item_AS_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
