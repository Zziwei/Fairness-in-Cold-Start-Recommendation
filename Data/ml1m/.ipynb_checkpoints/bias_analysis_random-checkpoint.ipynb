{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn import feature_selection\n",
    "import random\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './item_new2old_list_Random.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7256d264cb20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# name = 'DeepMusic'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# name = 'NLinMap'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mitem_new2old_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./item_new2old_list_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0muser_new2old_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./user_new2old_list_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mrank_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./rank_matrix_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/python3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './item_new2old_list_Random.npy'"
     ]
    }
   ],
   "source": [
    "# name = 'LLAE'\n",
    "name = 'random'\n",
    "# name = 'DeepMusic'\n",
    "# name = 'NLinMap'\n",
    "item_new2old_list = np.load('./item_new2old_list_' + name + '.npy')\n",
    "user_new2old_list = np.load('./user_new2old_list_' + name + '.npy')\n",
    "rank_matrix = np.load('./rank_matrix_' + name + '.npy')\n",
    "warm_test_df = pd.read_csv('./warm_test_df.csv')\n",
    "cold_test_df = pd.read_csv('./cold_test_df.csv')\n",
    "\n",
    "item_genre_dict_all = None\n",
    "with open('./item_genre_dict.pkl', 'rb') as f:\n",
    "    item_genre_dict_all = pickle.load(f)\n",
    "\n",
    "item_AS_list_all = np.load('./item_audience_size_list.npy')\n",
    "\n",
    "user_cold_test_like = list(np.load('./user_cold_test_like.npy', allow_pickle=True))\n",
    "user_warm_test_like = list(np.load('./user_warm_test_like.npy', allow_pickle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the old id to new id convertion lists for users and items\n",
    "item_old2new_id_dict = dict()\n",
    "user_old2new_id_dict = dict()\n",
    "for i in range(len(item_new2old_list)):\n",
    "    item_old2new_id_dict[item_new2old_list[i]] = i\n",
    "for u in range(len(user_new2old_list)):\n",
    "    user_old2new_id_dict[user_new2old_list[u]] = u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the item_genre_dict_all with items involed in test phase\n",
    "item_genre_dict = dict()\n",
    "for old_iid in item_genre_dict_all:\n",
    "    if old_iid in item_old2new_id_dict:\n",
    "        item_genre_dict[item_old2new_id_dict[old_iid]] = item_genre_dict_all[old_iid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the item_AS_list_all with items involed in test phase\n",
    "item_AS_list = np.zeros_like(item_new2old_list).astype(np.float32)\n",
    "for i in range(len(item_AS_list_all)):\n",
    "    if i in item_old2new_id_dict:\n",
    "        item_AS_list[item_old2new_id_dict[i]] = item_AS_list_all[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rank totally based on popularity\n",
    "# ranked_items = np.argsort(item_AS_list)\n",
    "# ranked_items = ranked_items[-1::-1]\n",
    "# n_rows = rank_matrix.shape[0]\n",
    "# rank_matrix = np.repeat(ranked_items.reshape((1, -1)), n_rows, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get warm_test_df with new id for user and item\n",
    "userIds = warm_test_df['uid'].values\n",
    "itemIds = warm_test_df['iid'].values\n",
    "userIdsNew = copy.copy(userIds)\n",
    "itemIdsNew = copy.copy(itemIds)\n",
    "for i in range(len(userIds)):\n",
    "    userIdsNew[i] = user_old2new_id_dict[userIds[i]]\n",
    "    itemIdsNew[i] = item_old2new_id_dict[itemIds[i]]\n",
    "warm_test_df = pd.DataFrame({'uid': userIdsNew, 'iid': itemIdsNew})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cold_test_df with new id for user and item\n",
    "userIds = cold_test_df['uid'].values\n",
    "itemIds = cold_test_df['iid'].values\n",
    "userIdsNew = copy.copy(userIds)\n",
    "itemIdsNew = copy.copy(itemIds)\n",
    "for i in range(len(userIds)):\n",
    "    userIdsNew[i] = user_old2new_id_dict[userIds[i]]\n",
    "    itemIdsNew[i] = item_old2new_id_dict[itemIds[i]]\n",
    "cold_test_df = pd.DataFrame({'uid': userIdsNew, 'iid': itemIdsNew})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get user_like_list for warm test\n",
    "warm_test_like = [[] for _ in range(len(user_new2old_list))] \n",
    "\n",
    "for old_uid in tqdm(range(len(user_warm_test_like))):\n",
    "    if old_uid in user_old2new_id_dict:\n",
    "        old_test_like = user_warm_test_like[old_uid]\n",
    "        test_like = []\n",
    "        for old_iid in old_test_like:\n",
    "            if old_iid in item_old2new_id_dict:\n",
    "                test_like.append(item_old2new_id_dict[old_iid])\n",
    "        warm_test_like[user_old2new_id_dict[old_uid]] = np.array(test_like).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get user_like_list for cold test\n",
    "cold_test_like = [[] for _ in range(len(user_new2old_list))] \n",
    "\n",
    "for old_uid in tqdm(range(len(user_cold_test_like))):\n",
    "    if old_uid in user_old2new_id_dict:\n",
    "        old_test_like = user_cold_test_like[old_uid]\n",
    "        test_like = []\n",
    "        for old_iid in old_test_like:\n",
    "            if old_iid in item_old2new_id_dict:\n",
    "                test_like.append(item_old2new_id_dict[old_iid])\n",
    "        cold_test_like[user_old2new_id_dict[old_uid]] = np.array(test_like).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_cold_test_like = cold_test_like\n",
    "user_warm_test_like = warm_test_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the rankings for matched users for each item \n",
    "k = 30\n",
    "\n",
    "item_AS_list = item_AS_list.astype(np.float32)\n",
    "\n",
    "item_hipop_list = np.where(item_AS_list >= 1500)[0]\n",
    "item_mipop_list = np.where((item_AS_list < 1500) & (item_AS_list >= 500))[0]\n",
    "item_lopop_list = np.where(item_AS_list < 500)[0]\n",
    "\n",
    "item_hipop_set = set(item_hipop_list)\n",
    "item_mipop_set = set(item_mipop_list)\n",
    "item_lopop_set = set(item_lopop_list)\n",
    "\n",
    "item_rank_count = np.zeros_like(item_AS_list)\n",
    "item_attention_count = np.zeros_like(item_AS_list)\n",
    "item_count = np.zeros_like(item_AS_list)\n",
    "u_recall = np.zeros_like(user_new2old_list).astype(np.float32)\n",
    "u_cold_recall = []\n",
    "u_warm_recall = []\n",
    "u_hipop_recall = []\n",
    "u_mipop_recall = []\n",
    "u_lopop_recall = []\n",
    "u_ndcg = np.zeros_like(user_new2old_list).astype(np.float32)\n",
    "u_cold_ndcg = []\n",
    "u_warm_ndcg = []\n",
    "u_hipop_ndcg = []\n",
    "u_mipop_ndcg = []\n",
    "u_lopop_ndcg = []\n",
    "cold_topk = 0.\n",
    "warm_topk = 0.\n",
    "cold_pos = 0.\n",
    "warm_pos = 0.\n",
    "for u in tqdm(range(len(user_new2old_list))):\n",
    "    u_rank_list = rank_matrix[u]\n",
    "    u_cold_like_set = set(user_cold_test_like[u])\n",
    "    u_warm_like_set = set(user_warm_test_like[u])\n",
    "    \n",
    "    u_like_set = u_cold_like_set.union(u_warm_like_set)\n",
    "    \n",
    "    u_hipop_like_set = u_like_set.intersection(item_hipop_set)\n",
    "    u_mipop_like_set = u_like_set.intersection(item_mipop_set)\n",
    "    u_lopop_like_set = u_like_set.intersection(item_lopop_set)\n",
    "    \n",
    "    n_like = len(u_like_set)\n",
    "    n_cold_like = len(u_cold_like_set)\n",
    "    n_warm_like = len(u_warm_like_set)\n",
    "    n_hipop_like = len(u_hipop_like_set)\n",
    "    n_mipop_like = len(u_mipop_like_set)\n",
    "    n_lopop_like = len(u_lopop_like_set)\n",
    "\n",
    "    recall_tmp = 0.\n",
    "    recall_warm_tmp = 0.\n",
    "    recall_cold_tmp = 0.\n",
    "    recall_hipop_tmp = 0.\n",
    "    recall_mipop_tmp = 0.\n",
    "    recall_lopop_tmp = 0.\n",
    "    \n",
    "    ndcg_tmp = 0.\n",
    "    ndcg_warm_tmp = 0.\n",
    "    ndcg_cold_tmp = 0.\n",
    "    ndcg_hipop_tmp = 0.\n",
    "    ndcg_mipop_tmp = 0.\n",
    "    ndcg_lopop_tmp = 0.\n",
    "\n",
    "    ndcg_de_tmp = 0.\n",
    "    ndcg_de_warm_tmp = 0.\n",
    "    ndcg_de_cold_tmp = 0.\n",
    "    ndcg_de_hipop_tmp = 0.\n",
    "    ndcg_de_mipop_tmp = 0.\n",
    "    ndcg_de_lopop_tmp = 0.\n",
    "    \n",
    "    match_item_set = set([])\n",
    "    for rank, iid in enumerate(u_rank_list):\n",
    "        if rank == k:\n",
    "            break\n",
    "            \n",
    "        if rank < n_like: ndcg_de_tmp += (1. / np.log2(rank + 2))\n",
    "        if rank < n_cold_like: ndcg_de_cold_tmp += (1. / np.log2(rank + 2))\n",
    "        if rank < n_warm_like: ndcg_de_warm_tmp += (1. / np.log2(rank + 2))\n",
    "        if rank < n_hipop_like: ndcg_de_hipop_tmp += (1. / np.log2(rank + 2))\n",
    "        if rank < n_mipop_like: ndcg_de_mipop_tmp += (1. / np.log2(rank + 2))\n",
    "        if rank < n_lopop_like: ndcg_de_lopop_tmp += (1. / np.log2(rank + 2))\n",
    "            \n",
    "        match = False\n",
    "        if iid in u_cold_like_set:\n",
    "            item_rank_count[iid] += (rank + 1)\n",
    "            item_attention_count[iid] += (1. / np.log2(rank + 2))\n",
    "            item_count[iid] += 1.\n",
    "            recall_tmp += 1.\n",
    "            recall_cold_tmp += 1.\n",
    "            ndcg_tmp += (1. / np.log2(rank + 2))\n",
    "            ndcg_cold_tmp += (1. / np.log2(rank + 2))\n",
    "            match_item_set.add(iid)\n",
    "            match = True\n",
    "        elif iid in u_warm_like_set:\n",
    "            item_rank_count[iid] += (rank + 1)\n",
    "            item_attention_count[iid] += (1. / np.log2(rank + 2))\n",
    "            item_count[iid] += 1.\n",
    "            recall_tmp += 1.\n",
    "            recall_warm_tmp += 1.\n",
    "            ndcg_tmp += (1. / np.log2(rank + 2))\n",
    "            ndcg_warm_tmp += (1. / np.log2(rank + 2))\n",
    "            match_item_set.add(iid)\n",
    "            match = True\n",
    "        \n",
    "        if match:\n",
    "            if iid in u_hipop_like_set: \n",
    "                ndcg_hipop_tmp += (1. / np.log2(rank + 2))\n",
    "                recall_hipop_tmp += 1.\n",
    "            elif iid in u_mipop_like_set: \n",
    "                ndcg_mipop_tmp += (1. / np.log2(rank + 2))\n",
    "                recall_mipop_tmp += 1.\n",
    "            elif iid in u_lopop_like_set: \n",
    "                ndcg_lopop_tmp += (1. / np.log2(rank + 2))\n",
    "                recall_lopop_tmp += 1.\n",
    "            \n",
    "    unmatch_item_set = u_like_set - match_item_set\n",
    "    for iid in unmatch_item_set:\n",
    "        item_rank_count[iid] += (k + 1)\n",
    "        item_attention_count[iid] += 0.\n",
    "        item_count[iid] += 1.\n",
    "    u_recall[u] = recall_tmp / (len(u_cold_like_set) + len(u_warm_like_set))\n",
    "    u_ndcg[u] = ndcg_tmp / ndcg_de_tmp\n",
    "    if len(u_cold_like_set) > 0: \n",
    "        u_cold_recall.append(recall_cold_tmp / (len(u_cold_like_set) + 1e-10))\n",
    "        u_cold_ndcg.append(ndcg_cold_tmp / ndcg_de_cold_tmp)\n",
    "    if len(u_warm_like_set) > 0: \n",
    "        u_warm_recall.append(recall_warm_tmp / (len(u_warm_like_set) + 1e-10))\n",
    "        u_warm_ndcg.append(ndcg_warm_tmp / ndcg_de_warm_tmp)\n",
    "    if len(u_hipop_like_set) > 0: \n",
    "        u_hipop_recall.append(recall_hipop_tmp / (len(u_hipop_like_set) + 1e-10))\n",
    "        u_hipop_ndcg.append(ndcg_hipop_tmp / ndcg_de_hipop_tmp)\n",
    "    if len(u_mipop_like_set) > 0: \n",
    "        u_mipop_recall.append(recall_mipop_tmp / (len(u_mipop_like_set) + 1e-10))\n",
    "        u_mipop_ndcg.append(ndcg_mipop_tmp / ndcg_de_mipop_tmp)\n",
    "    if len(u_lopop_like_set) > 0: \n",
    "        u_lopop_recall.append(recall_lopop_tmp / (len(u_lopop_like_set) + 1e-10))\n",
    "        u_lopop_ndcg.append(ndcg_lopop_tmp / ndcg_de_lopop_tmp)\n",
    "    cold_topk += recall_cold_tmp\n",
    "    warm_topk += recall_warm_tmp\n",
    "    cold_pos += len(u_cold_like_set)\n",
    "    warm_pos += len(u_warm_like_set)\n",
    "\n",
    "print('probability of being ranked in top-30 for cold = ' + str(cold_topk / cold_pos))\n",
    "print('probability of being ranked in top-30 for warm = ' + str(warm_topk / warm_pos))\n",
    "print('-' * 50)\n",
    "print('recall@k = ' + str(np.mean(u_recall)))\n",
    "print('recall@k for cold = ' + str(np.mean(u_cold_recall)))\n",
    "print('recall@k for warm = ' + str(np.mean(u_warm_recall)))\n",
    "print('recall@k for hipop = ' + str(np.mean(u_hipop_recall)))\n",
    "print('recall@k for mipop = ' + str(np.mean(u_mipop_recall)))\n",
    "print('recall@k for lopop = ' + str(np.mean(u_lopop_recall)))\n",
    "print('-' * 50)\n",
    "print('ndcg@k = ' + str(np.mean(u_ndcg)))\n",
    "print('ndcg@k for cold = ' + str(np.mean(u_cold_ndcg)))\n",
    "print('ndcg@k for warm = ' + str(np.mean(u_warm_ndcg)))\n",
    "print('ndcg@k for hipop = ' + str(np.mean(u_hipop_ndcg)))\n",
    "print('ndcg@k for mipop = ' + str(np.mean(u_mipop_ndcg)))\n",
    "print('ndcg@k for lopop = ' + str(np.mean(u_lopop_ndcg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average metrics for all items\n",
    "item_avg_attention = item_attention_count / (item_count + 1e-7)\n",
    "\n",
    "warm_idx = warm_test_df['iid'].unique()\n",
    "cold_idx = cold_test_df['iid'].unique()\n",
    "hipop_idx = item_hipop_list\n",
    "mipop_idx = item_mipop_list\n",
    "lopop_idx = item_lopop_list\n",
    "\n",
    "item_cold_avg_attention = item_avg_attention[cold_idx]\n",
    "item_warm_avg_attention = item_avg_attention[warm_idx]\n",
    "item_hipop_avg_attention = item_avg_attention[hipop_idx]\n",
    "item_mipop_avg_attention = item_avg_attention[mipop_idx]\n",
    "item_lopop_avg_attention = item_avg_attention[lopop_idx]\n",
    "\n",
    "print('avg attention for all = ' + str(np.mean(item_avg_attention)))\n",
    "print('avg attention for warm = ' + str(np.mean(item_warm_avg_attention)))\n",
    "print('avg attention for cold = ' + str(np.mean(item_cold_avg_attention)))\n",
    "print('avg attention for hipop = ' + str(np.mean(item_hipop_avg_attention)))\n",
    "print('avg attention for mipop = ' + str(np.mean(item_mipop_avg_attention)))\n",
    "print('avg attention for lopop = ' + str(np.mean(item_lopop_avg_attention)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the rankings for matched users for each item \n",
    "k = 500\n",
    "\n",
    "all_item_att_count = np.zeros_like(item_AS_list)\n",
    "all_item_rank_count = np.zeros_like(item_AS_list)\n",
    "\n",
    "item_AS_list = item_AS_list.astype(np.float32)\n",
    "item_rank_count = np.zeros_like(item_AS_list)\n",
    "item_rrank_count = np.zeros_like(item_AS_list)\n",
    "item_attention_count = np.zeros_like(item_AS_list)\n",
    "item_count = np.zeros_like(item_AS_list)\n",
    "u_recall = np.zeros_like(user_new2old_list).astype(np.float32)\n",
    "for u in tqdm(range(len(user_new2old_list))):\n",
    "    u_rank_list = rank_matrix[u]\n",
    "    u_cold_like_set = set(user_cold_test_like[u])\n",
    "    u_warm_like_set = set(user_warm_test_like[u])\n",
    "    recall_tmp = 0.\n",
    "    \n",
    "    match_item_set = set([])\n",
    "    u_all_item_rank = np.ones_like(item_AS_list) * (k + 1)\n",
    "    u_all_item_att = np.zeros_like(item_AS_list)\n",
    "    for rank, iid in enumerate(u_rank_list):\n",
    "        u_all_item_rank[iid] = rank\n",
    "        u_all_item_att[iid] = (1. / np.log2(rank + 2))\n",
    "        if rank == k:\n",
    "            break\n",
    "        if iid in u_cold_like_set or iid in u_warm_like_set:\n",
    "            item_rank_count[iid] += (rank + 1)\n",
    "            item_rrank_count[iid] += (1. / (rank + 1))\n",
    "            item_attention_count[iid] += (1. / np.log2(rank + 2))\n",
    "            item_count[iid] += 1.\n",
    "            recall_tmp += 1.\n",
    "            match_item_set.add(iid)\n",
    "            \n",
    "    all_item_rank_count += u_all_item_rank\n",
    "    all_item_att_count += u_all_item_att\n",
    "            \n",
    "    unmatch_item_set = u_cold_like_set.union(u_warm_like_set) - match_item_set\n",
    "    for iid in unmatch_item_set:\n",
    "        item_rank_count[iid] += (k + 1)\n",
    "#         item_rrank_count[iid] += (1. / (k + 1))\n",
    "#         item_attention_count[iid] += (1. / np.log2(k + 2))\n",
    "        item_rrank_count[iid] += 0.\n",
    "        item_attention_count[iid] += 0.\n",
    "        item_count[iid] += 1.\n",
    "    u_recall[u] = recall_tmp / (len(u_cold_like_set) + len(u_warm_like_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(u_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average metrics for all items\n",
    "item_avg_rank = item_rank_count / (item_count + 1e-7)\n",
    "item_avg_rrank = item_rrank_count / (item_count + 1e-7)\n",
    "item_avg_attention = item_attention_count / (item_count + 1e-7)\n",
    "\n",
    "all_item_avg_rank = all_item_rank_count / len(user_new2old_list)\n",
    "all_item_avg_att = all_item_att_count / len(user_new2old_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_idx = np.where(item_AS_list >= 10)[0]\n",
    "warm_idx = warm_test_df['iid'].unique()\n",
    "cold_idx = cold_test_df['iid'].unique()\n",
    "keep_warm_idx = np.array(list(set(list(warm_idx)).intersection(set(list(keep_idx)))))\n",
    "keep_cold_idx = np.array(list(set(list(cold_idx)).intersection(set(list(keep_idx)))))\n",
    "print('#all warm items in test:' + str(len(warm_idx)))\n",
    "print('#all cold items in test:' + str(len(cold_idx)))\n",
    "print('#filtered warm items in test:' + str(len(keep_warm_idx)) + ' (' + str(len(keep_warm_idx) / len(warm_idx)) + ')')\n",
    "print('#filtered cold items in test:' + str(len(keep_cold_idx)) + ' (' + str(len(keep_cold_idx) / len(cold_idx)) + ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_cold_pop = item_AS_list[keep_cold_idx]\n",
    "item_warm_pop = item_AS_list[keep_warm_idx]\n",
    "item_cold_avg_rank = item_avg_rank[keep_cold_idx]\n",
    "item_warm_avg_rank = item_avg_rank[keep_warm_idx]\n",
    "item_cold_avg_rrank = item_avg_rrank[keep_cold_idx]\n",
    "item_warm_avg_rrank = item_avg_rrank[keep_warm_idx]\n",
    "item_cold_avg_attention = item_avg_attention[keep_cold_idx]\n",
    "item_warm_avg_attention = item_avg_attention[keep_warm_idx]\n",
    "\n",
    "all_item_cold_avg_rank = all_item_avg_rank[keep_cold_idx]\n",
    "all_item_warm_avg_rank = all_item_avg_rank[keep_warm_idx]\n",
    "all_item_cold_avg_att = all_item_avg_att[keep_cold_idx]\n",
    "all_item_warm_avg_att = all_item_avg_att[keep_warm_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_rank = [('IMAX', 438.2),\n",
    " ('Sci-Fi', 335.6886446886447),\n",
    " ('Adventure', 307.9732620320856),\n",
    " ('Action', 302.2536997885835),\n",
    " ('Fantasy', 280.4867724867725),\n",
    " ('Animation', 253.96116504854368),\n",
    " ('Crime', 242.76993865030676),\n",
    " ('Thriller', 239.53251318101934),\n",
    " ('Mystery', 228.67857142857142),\n",
    " ('War', 226.34710743801654),\n",
    " ('Musical', 217.70992366412213),\n",
    " ('Film-Noir', 214.675),\n",
    " ('Comedy', 203.06569343065692),\n",
    " ('Romance', 199.30258302583024),\n",
    " ('Western', 195.15942028985506),\n",
    " ('Children', 177.66796875),\n",
    " ('Drama', 170.85956245589273),\n",
    " ('Horror', 165.27388535031847),\n",
    " ('Documentary', 73.98245614035088)]\n",
    "genres = []\n",
    "genre_color_dict = dict()\n",
    "import matplotlib.colors as colors\n",
    "np.random.seed(0)\n",
    "colors_list = list(colors._colors_full_map.values())\n",
    "np.random.shuffle(colors_list)\n",
    "for i in range(len(genre_rank)):\n",
    "    genres.append(genre_rank[i][0])\n",
    "    genre_color_dict[genre_rank[i][0]] = colors_list[i]\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(14, 9))\n",
    "gap = 0.1\n",
    "x = np.arange(1)  # the label locations\n",
    "width = 1  # the width of the bars\n",
    "start = 0.5 * (int(len(genre_rank) + 1) % 2) + len(genre_rank) - 1\n",
    "position = np.arange(start, -1 * start - 1, -1)\n",
    "for i in range(len(genre_rank)):\n",
    "    axes.bar(0 - width*position[i], genre_rank[i][1], width-gap, label=genre_rank[i][0], alpha=0.8, color=genre_color_dict[genre_rank[i][0]])\n",
    "axes.set_ylabel('Avg Reciprocal Rank of Genres')\n",
    "axes.set_title('#feedback/#item in training data')\n",
    "plt.legend(loc='center left',  bbox_to_anchor=(1, 0.5))\n",
    "axes.set_xticklabels([''])\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_avg_rank_dict = dict()\n",
    "genre_avg_rrank_dict = dict()\n",
    "genre_avg_attention_dict = dict()\n",
    "genre_count_dict = dict()\n",
    "for g in genres:\n",
    "    genre_avg_rank_dict[g] = 0.\n",
    "    genre_avg_rrank_dict[g] = 0.\n",
    "    genre_avg_attention_dict[g] = 0.\n",
    "    genre_count_dict[g] = 0.\n",
    "for iid in keep_idx:\n",
    "    i_genres = item_genre_dict[iid]\n",
    "    i_avg_rank = item_avg_rank[iid]\n",
    "    i_avg_rrank = item_avg_rrank[iid]\n",
    "    i_avg_attention = item_avg_attention[iid]\n",
    "    for g in i_genres:\n",
    "        genre_avg_rank_dict[g] += i_avg_rank\n",
    "        genre_avg_rrank_dict[g] += i_avg_rrank\n",
    "        genre_avg_attention_dict[g] += i_avg_attention\n",
    "        genre_count_dict[g] += 1.\n",
    "\n",
    "for g in genres:\n",
    "    count = genre_count_dict[g]\n",
    "    genre_avg_rank_dict[g] /= count\n",
    "    genre_avg_rrank_dict[g] /= count\n",
    "    genre_avg_attention_dict[g] /= count\n",
    "\n",
    "        \n",
    "# genre_sorted = sorted(genre_avg_rank_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "# print(genre_sorted)\n",
    "# genre_sorted = sorted(genre_avg_rrank_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "# print(genre_sorted)\n",
    "genre_sorted = sorted(genre_avg_attention_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "print(genre_sorted)\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(14, 9))\n",
    "gap = 0.1\n",
    "x = np.arange(1)  # the label locations\n",
    "width = 1  # the width of the bars\n",
    "for i in range(len(genre_sorted)):\n",
    "    axes.bar(0 - width*position[i], genre_sorted[i][1], width-gap, label=genre_sorted[i][0], alpha=0.8, color=genre_color_dict[genre_sorted[i][0]])\n",
    "axes.set_ylabel('Avg Attention of Genres')\n",
    "plt.legend(loc='center left',  bbox_to_anchor=(1, 0.5))\n",
    "axes.set_xticklabels([''])\n",
    "axes.set_ylim(0, 0.18)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_avg_rank_dict = dict()\n",
    "genre_avg_rrank_dict = dict()\n",
    "genre_avg_attention_dict = dict()\n",
    "genre_count_dict = dict()\n",
    "for g in genres:\n",
    "    genre_avg_rank_dict[g] = 0.\n",
    "    genre_avg_rrank_dict[g] = 0.\n",
    "    genre_avg_attention_dict[g] = 0.\n",
    "    genre_count_dict[g] = 0.\n",
    "for iid in keep_warm_idx:\n",
    "    i_genres = item_genre_dict[iid]\n",
    "    i_avg_rank = item_avg_rank[iid]\n",
    "    i_avg_rrank = item_avg_rrank[iid]\n",
    "    i_avg_attention = item_avg_attention[iid]\n",
    "    for g in i_genres:\n",
    "        genre_avg_rank_dict[g] += i_avg_rank\n",
    "        genre_avg_rrank_dict[g] += i_avg_rrank\n",
    "        genre_avg_attention_dict[g] += i_avg_attention\n",
    "        genre_count_dict[g] += 1.\n",
    "\n",
    "for g in genres:\n",
    "    count = genre_count_dict[g]\n",
    "    genre_avg_rank_dict[g] /= count\n",
    "    genre_avg_rrank_dict[g] /= count\n",
    "    genre_avg_attention_dict[g] /= count\n",
    "\n",
    "        \n",
    "# genre_sorted = sorted(genre_avg_rank_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "# print(genre_sorted)\n",
    "# genre_sorted = sorted(genre_avg_rrank_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "# print(genre_sorted)\n",
    "genre_sorted = sorted(genre_avg_attention_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "print(genre_sorted)\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(14, 9))\n",
    "gap = 0.1\n",
    "x = np.arange(1)  # the label locations\n",
    "width = 1  # the width of the bars\n",
    "for i in range(len(genre_sorted)):\n",
    "    axes.bar(0 - width*position[i], genre_sorted[i][1], width-gap, label=genre_sorted[i][0], alpha=0.8, color=genre_color_dict[genre_sorted[i][0]])\n",
    "axes.set_ylabel('Avg Attention of Genres')\n",
    "axes.set_title('Att for warm items')\n",
    "plt.legend(loc='center left',  bbox_to_anchor=(1, 0.5))\n",
    "axes.set_xticklabels([''])\n",
    "axes.set_ylim(0, 0.18)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_avg_rank_dict = dict()\n",
    "genre_avg_rrank_dict = dict()\n",
    "genre_avg_attention_dict = dict()\n",
    "genre_count_dict = dict()\n",
    "for g in genres:\n",
    "    genre_avg_rank_dict[g] = 0.\n",
    "    genre_avg_rrank_dict[g] = 0.\n",
    "    genre_avg_attention_dict[g] = 0.\n",
    "    genre_count_dict[g] = 0.\n",
    "for iid in keep_cold_idx:\n",
    "    i_genres = item_genre_dict[iid]\n",
    "    i_avg_rank = item_avg_rank[iid]\n",
    "    i_avg_rrank = item_avg_rrank[iid]\n",
    "    i_avg_attention = item_avg_attention[iid]\n",
    "    for g in i_genres:\n",
    "        genre_avg_rank_dict[g] += i_avg_rank\n",
    "        genre_avg_rrank_dict[g] += i_avg_rrank\n",
    "        genre_avg_attention_dict[g] += i_avg_attention\n",
    "        genre_count_dict[g] += 1.\n",
    "\n",
    "for g in genres:\n",
    "    count = genre_count_dict[g]\n",
    "    genre_avg_rank_dict[g] /= count\n",
    "    genre_avg_rrank_dict[g] /= count\n",
    "    genre_avg_attention_dict[g] /= count\n",
    "\n",
    "        \n",
    "# genre_sorted = sorted(genre_avg_rank_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "# print(genre_sorted)\n",
    "# genre_sorted = sorted(genre_avg_rrank_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "# print(genre_sorted)\n",
    "genre_sorted = sorted(genre_avg_attention_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "print(genre_sorted)\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(14, 9))\n",
    "gap = 0.1\n",
    "x = np.arange(1)  # the label locations\n",
    "width = 1  # the width of the bars\n",
    "for i in range(len(genre_sorted)):\n",
    "    axes.bar(0 - width*position[i], genre_sorted[i][1], width-gap, label=genre_sorted[i][0], alpha=0.8, color=genre_color_dict[genre_sorted[i][0]])\n",
    "axes.set_ylabel('Avg Attention of Genres')\n",
    "axes.set_title('Att for cold items')\n",
    "plt.legend(loc='center left',  bbox_to_anchor=(1, 0.5))\n",
    "axes.set_xticklabels([''])\n",
    "axes.set_ylim(0, 0.18)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_avg_rank = item_avg_rank[keep_idx]\n",
    "item_avg_rrank = item_avg_rrank[keep_idx]\n",
    "item_avg_attention = item_avg_attention[keep_idx]\n",
    "item_AS_list = item_AS_list[keep_idx]\n",
    "\n",
    "all_item_avg_rank = all_item_avg_rank[keep_idx]\n",
    "all_item_avg_att = all_item_avg_att[keep_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('PCC rank = ' + str(stats.pearsonr(item_avg_rank + 1e-7, item_AS_list + 1e-7)))  # spearmanr\n",
    "print('PCC rrank = ' + str(stats.pearsonr(item_avg_rrank + 1e-7, item_AS_list + 1e-7)))\n",
    "print('PCC attention = ' + str(stats.pearsonr(item_avg_attention + 1e-7, item_AS_list + 1e-7)))\n",
    "print('MI attention = ' + str(feature_selection.mutual_info_regression(item_avg_attention.reshape((-1, 1)), item_AS_list)[0]))\n",
    "x = item_AS_list.reshape((-1, 1))\n",
    "X = np.concatenate((np.ones_like(x), x), axis=1)\n",
    "y = item_avg_attention.reshape((-1, 1))\n",
    "w = np.matmul(np.matmul(np.linalg.inv(np.matmul(X.T, X)), X.T), y)\n",
    "print('Slope attention = ' + str(w[1, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('for cold items:')\n",
    "print('PCC rank = ' + str(stats.pearsonr(item_cold_avg_rank + 1e-7, item_cold_pop + 1e-7)))\n",
    "print('PCC rrank = ' + str(stats.pearsonr(item_cold_avg_rrank + 1e-7, item_cold_pop + 1e-7)))\n",
    "print('PCC attention = ' + str(stats.pearsonr(item_cold_avg_attention + 1e-7, item_cold_pop + 1e-7)))\n",
    "print('MI attention = ' + str(feature_selection.mutual_info_regression(item_cold_avg_attention.reshape((-1, 1)), item_cold_pop)[0]))\n",
    "x = item_cold_pop.reshape((-1, 1))\n",
    "X = np.concatenate((np.ones_like(x), x), axis=1)\n",
    "y = item_cold_avg_attention.reshape((-1, 1))\n",
    "w = np.matmul(np.matmul(np.linalg.inv(np.matmul(X.T, X)), X.T), y)\n",
    "print('Slope attention = ' + str(w[1, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('for warm items:')\n",
    "print('PCC rank = ' + str(stats.pearsonr(item_warm_avg_rank + 1e-7, item_warm_pop + 1e-7)))\n",
    "print('PCC rrank = ' + str(stats.pearsonr(item_warm_avg_rrank + 1e-7, item_warm_pop + 1e-7)))\n",
    "print('PCC attention = ' + str(stats.pearsonr(item_warm_avg_attention + 1e-7, item_warm_pop + 1e-7)))\n",
    "print('MI attention = ' + str(feature_selection.mutual_info_regression(item_warm_avg_attention.reshape((-1, 1)), item_warm_pop)[0]))\n",
    "x = item_warm_pop.reshape((-1, 1))\n",
    "X = np.concatenate((np.ones_like(x), x), axis=1)\n",
    "y = item_warm_avg_attention.reshape((-1, 1))\n",
    "w = np.matmul(np.matmul(np.linalg.inv(np.matmul(X.T, X)), X.T), y)\n",
    "print('Slope attention = ' + str(w[1, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploting\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(14, 9))\n",
    "\n",
    "axes.scatter(item_warm_pop, item_warm_avg_rank, alpha=0.9, label='warm items')\n",
    "axes.scatter(item_cold_pop, item_cold_avg_rank, alpha=0.9, label='cold items', marker='^')\n",
    "\n",
    "axes.set_ylabel('Avg rank for matched users')\n",
    "axes.set_xlabel('Audience size')\n",
    "axes.legend()\n",
    "axes.grid(True)\n",
    "axes.set_ylim(0, k)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploting\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(14, 9))\n",
    "\n",
    "axes.scatter(item_warm_pop, item_warm_avg_rrank, alpha=0.9, label='warm items')\n",
    "axes.scatter(item_cold_pop, item_cold_avg_rrank, alpha=0.9, label='cold items', marker='^')\n",
    "\n",
    "axes.set_ylabel('Avg reciprocal rank for matched users')\n",
    "axes.set_xlabel('Audience size')\n",
    "axes.legend()\n",
    "axes.grid(True)\n",
    "axes.set_ylim(0., 0.4)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ploting\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(14, 9))\n",
    "\n",
    "axes.scatter(item_warm_pop, item_warm_avg_attention, alpha=0.9, label='warm items')\n",
    "axes.scatter(item_cold_pop, item_cold_avg_attention, alpha=0.9, label='cold items', marker='^')\n",
    "\n",
    "axes.set_ylabel('Avg attention from matched users')\n",
    "axes.set_xlabel('Audience size')\n",
    "axes.legend()\n",
    "axes.grid(True)\n",
    "axes.set_ylim(0., 0.7)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('for cold items:')\n",
    "print('avg rank = ' + str(np.mean(item_cold_avg_rank)))\n",
    "print('avg rrank = ' + str(np.mean(item_cold_avg_rrank)))\n",
    "print('avg attention = ' + str(np.mean(item_cold_avg_attention)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('for warm items:')\n",
    "print('avg rank = ' + str(np.mean(item_warm_avg_rank)))\n",
    "print('avg rrank = ' + str(np.mean(item_warm_avg_rrank)))\n",
    "print('avg attention = ' + str(np.mean(item_warm_avg_attention)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean of item audience size = ' + str(np.mean(item_AS_list)))\n",
    "print('Std of item audience size = ' + str(np.std(item_AS_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ploting\n",
    "# plt.rcParams.update({'font.size': 22})\n",
    "# fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(14, 9))\n",
    "\n",
    "# axes.plot(np.arange(len(item_AS_list)), np.sort(item_AS_list))\n",
    "\n",
    "# axes.grid(True)\n",
    "\n",
    "\n",
    "# fig.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploting\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 6))\n",
    "\n",
    "axes.scatter(item_warm_pop, all_item_warm_avg_rank, alpha=0.9, label='warm items')\n",
    "axes.scatter(item_cold_pop, all_item_cold_avg_rank, alpha=0.4, label='cold items')\n",
    "\n",
    "axes.set_ylabel('Avg rank')\n",
    "axes.set_xlabel('Audience size')\n",
    "axes.legend()\n",
    "axes.grid(True)\n",
    "axes.set_ylim(0, k)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploting\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 6))\n",
    "\n",
    "axes.scatter(item_warm_pop, all_item_warm_avg_att, alpha=0.9, label='warm items')\n",
    "axes.scatter(item_cold_pop, all_item_cold_avg_att, alpha=0.4, label='cold items')\n",
    "\n",
    "axes.set_ylabel('Avg attention')\n",
    "axes.set_xlabel('Audience size')\n",
    "axes.legend()\n",
    "axes.grid(True)\n",
    "axes.set_ylim(0, 0.5)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
